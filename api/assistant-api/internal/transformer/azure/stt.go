// Copyright (c) 2023-2025 RapidaAI
// Author: Prashant Srivastav <prashant@rapida.ai>
//
// Licensed under GPL-2.0 with Rapida Additional Terms.
// See LICENSE.md or contact sales@rapida.ai for commercial usage.

package internal_transformer_azure

import (
	"context"
	"fmt"
	"sync"

	"github.com/Microsoft/cognitive-services-speech-sdk-go/audio"
	"github.com/Microsoft/cognitive-services-speech-sdk-go/speech"
	internal_transformer "github.com/rapidaai/api/assistant-api/internal/transformer"
	internal_type "github.com/rapidaai/api/assistant-api/internal/type"
	"github.com/rapidaai/pkg/commons"
	"github.com/rapidaai/protos"
)

type azureSpeechToText struct {
	*azureOption
	mu sync.Mutex

	// context management
	ctx       context.Context
	ctxCancel context.CancelFunc

	logger            commons.Logger
	client            *speech.SpeechRecognizer
	azureAudioConfig  *audio.AudioConfig
	inputstream       *audio.PushAudioInputStream
	transformerOption *internal_transformer.SpeechToTextInitializeOptions
}

func (azure *azureSpeechToText) Initialize() (err error) {
	inputstream, err := audio.CreatePushAudioInputStreamFromFormat(azure.GetAudioStreamFormat())
	if err != nil {
		azure.logger.Errorf("azure-stt: failed to create push audio input stream: %v", err)
		return fmt.Errorf("failed to create push audio input stream: %w", err)
	}

	azureAudioConfig, err := audio.NewAudioConfigFromStreamInput(inputstream)
	if err != nil {
		azure.logger.Errorf("azure-stt: failed to create audio config from stream input: %v", err)
		return fmt.Errorf("failed to create audio config from stream input: %w", err)
	}

	speechConfig, err := azure.SpeechToTextOption()
	if err != nil {
		azure.logger.Errorf("azure-stt: failed to create speech config from subscription: %v", err)
		return fmt.Errorf("failed to create speech config from subscription: %w", err)
	}

	client, err := speech.NewSpeechRecognizerFromConfig(speechConfig, azureAudioConfig)
	if err != nil {
		azure.logger.Errorf("azure-stt: failed to create speech recognizer from config: %v", err)
		return fmt.Errorf("failed to create speech recognizer from config: %w", err)
	}

	azure.mu.Lock()
	azure.client = client
	azure.azureAudioConfig = azureAudioConfig
	azure.inputstream = inputstream
	azure.mu.Unlock()

	azure.client.SessionStarted(azure.OnSessionStarted)
	azure.client.SessionStopped(azure.OnSessionStopped)
	azure.client.Recognizing(azure.OnRecognizing)
	azure.client.Recognized(azure.OnRecognized)
	azure.client.Canceled(azure.OnCancelled)
	azure.client.StartContinuousRecognitionAsync()

	return nil
}

// Name implements internal_transformer.SpeechToTextTransformer.
func (a *azureSpeechToText) Name() string {
	return "azure-speech-to-text"
}

// Transform implements internal_transformer.SpeechToTextTransformer.
func (azure *azureSpeechToText) Transform(ctx context.Context, ad []byte) (err error) {
	azure.mu.Lock()
	stream := azure.inputstream
	azure.mu.Unlock()

	if stream == nil {
		return fmt.Errorf("azure-stt: transform called before initialize")
	}

	if err := stream.Write(ad); err != nil {
		return fmt.Errorf("failed to write audio data: %w", err)
	}
	return nil
}

func NewAzureSpeechToText(ctx context.Context, logger commons.Logger, credential *protos.VaultCredential, iOptions *internal_transformer.SpeechToTextInitializeOptions) (internal_transformer.SpeechToTextTransformer, error) {
	azure, err := NewAzureOption(logger, credential, iOptions.AudioConfig, iOptions.ModelOptions)
	if err != nil {
		logger.Errorf("azure-stt: Unable to initilize azure option", err)
		return nil, err
	}

	ct, ctxCancel := context.WithCancel(ctx)
	return &azureSpeechToText{
		ctx:       ct,
		ctxCancel: ctxCancel,

		logger:            logger,
		transformerOption: iOptions,
		azureOption:       azure,
	}, nil
}

func (azCallback *azureSpeechToText) OnSessionStarted(event speech.SessionEventArgs) {
	defer event.Close()
}

func (azCallback *azureSpeechToText) OnSessionStopped(event speech.SessionEventArgs) {
	defer event.Close()
}

func (az *azureSpeechToText) OnRecognizing(event speech.SpeechRecognitionEventArgs) {
	defer event.Close()
	if az.transformerOption != nil {
		az.transformerOption.OnPacket(internal_type.SpeechToTextPacket{
			Script:     event.Result.Text,
			Confidence: 0.9,
			Language:   "en",
			Interim:    true,
		})
	}
}

func (az *azureSpeechToText) OnRecognized(event speech.SpeechRecognitionEventArgs) {
	defer event.Close()
	if az.transformerOption != nil {
		az.transformerOption.OnPacket(internal_type.SpeechToTextPacket{
			Script:     event.Result.Text,
			Confidence: 0.9,
			Language:   "en",
			Interim:    false,
		})
	}
}

func (azCallback *azureSpeechToText) OnCancelled(event speech.SpeechRecognitionCanceledEventArgs) {
	defer event.Close()
}

// Cancel implements internal_transformer.SpeechToTextTransformer.
func (azure *azureSpeechToText) Close(ctx context.Context) error {
	azure.ctxCancel()

	azure.mu.Lock()
	defer azure.mu.Unlock()

	if azure.client != nil {
		azure.client.StopContinuousRecognitionAsync()
		azure.client.Close()
	}
	if azure.inputstream != nil {
		azure.inputstream.Close()
	}
	if azure.azureAudioConfig != nil {
		azure.azureAudioConfig.Close()
	}
	return nil
}
